{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Making vgg16\n"
      ],
      "metadata": {
        "id": "wqk0fiKdLuWp"
      },
      "id": "wqk0fiKdLuWp"
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision import datasets\n",
        "from torchvision import transforms\n",
        "from torch.utils.data.sampler import SubsetRandomSampler"
      ],
      "metadata": {
        "id": "m724tJ5OLyc1"
      },
      "id": "m724tJ5OLyc1",
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Device config\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "device\n"
      ],
      "metadata": {
        "id": "djwZiAPwMT0A",
        "outputId": "0c7d043f-62a3-44db-bb64-b7becd5868ee",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "djwZiAPwMT0A",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cpu')"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Data Loader\n",
        "def data_loader(data_dir,batch_size,random_seed=42,valid_size=0.1,shuffle=True,test=False):\n",
        "  transforms.Normalize(\n",
        "      mean=[0.4914, 0.4822, 0.4465],\n",
        "      std=[0.2023, 0.1994, 0.2010]\n",
        "  )\n",
        "\n",
        "  #defining transforms\n",
        "\n",
        "  transform =transforms.compose([\n",
        "      transform.Resize((227,227)),\n",
        "      transform.ToTensor(),\n",
        "      Normalize\n",
        "\n",
        "  ])\n",
        "\n",
        "  if test:\n",
        "    dataset = datasets.CIFAR10(\n",
        "        root=data_dir,train=False,download=True,transform=transform\n",
        "    )\n",
        "\n",
        "    data_loader = torch.utils.data.DataLoader(\n",
        "        dataset,batch_size=batch_size,shuffle=shuffle\n",
        "    )\n",
        "\n",
        "    return data_loader\n",
        "\n",
        "    #load dataset\n",
        "\n",
        "    dataset = datasets.CIFAR10(\n",
        "        root=data_dir,train=True,download=True,transform=transform\n",
        "    )\n",
        "\n",
        "    validate_dataset = datasets.CIFAR10(\n",
        "        root=data_dir,train=True,download=True,transform=transform\n",
        "    )\n",
        "\n",
        "    num_train = len(train_dataset)\n",
        "    indices = list(range(num_train))\n",
        "    split = int(np.floor(valid_size*num_train))\n",
        "\n",
        "    if shuffle:\n",
        "      np.random.seed(random_seed)\n",
        "      np.random.shuffle(indices)\n",
        "\n",
        "    train_idx,test_idx = indices[split:],indices[:split]\n",
        "\n",
        "    train_sampler = SubsetRandomSampler(train_idx)\n",
        "    test_sampler = SubsetRandomSampler(test_idx)\n",
        "\n",
        "    train_loader = torch.utils.data.DataLoader(\n",
        "        dataset,batch_size=batch_size,sampler=train_sampler\n",
        "    )\n",
        "\n",
        "    test_loader = torch.utils.data.DataLoader(\n",
        "        validate_dataset,batch_size=batch_size,sampler=test_sampler\n",
        "    )\n",
        "\n",
        "    return (train_loader,test_loader)\n",
        "\n",
        "    valid_loadr = torch.utils.DataLoader(\n",
        "        validate_dataset,batch_size=batch_size,shuffle=valid_sampler\n",
        "    )\n",
        "\n",
        "    return(train_loader , valid_loader)"
      ],
      "metadata": {
        "id": "wztsAvN4M4dl"
      },
      "id": "wztsAvN4M4dl",
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader,test_loader = data_loader(data_dir='./data',batch_size=64)"
      ],
      "metadata": {
        "id": "ctOzRwXaWHkY",
        "outputId": "c6a742f2-ba0a-4963-9c5f-512b3b2caa18",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 332
        }
      },
      "id": "ctOzRwXaWHkY",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "module 'torchvision.transforms' has no attribute 'compose'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-6057f4228de2>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest_loader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_loader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'./data'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-4-1392df1bd75d>\u001b[0m in \u001b[0;36mdata_loader\u001b[0;34m(data_dir, batch_size, random_seed, valid_size, shuffle, test)\u001b[0m\n\u001b[1;32m      8\u001b[0m   \u001b[0;31m#defining transforms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m   transform =transforms.compose([\n\u001b[0m\u001b[1;32m     11\u001b[0m       \u001b[0mtransform\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mResize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m227\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m227\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m       \u001b[0mtransform\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mToTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: module 'torchvision.transforms' has no attribute 'compose'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jAPTiUVoWHn7"
      },
      "id": "jAPTiUVoWHn7",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Jv1aGF3JWHzL"
      },
      "id": "Jv1aGF3JWHzL",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BHAc0zehWH2i"
      },
      "id": "BHAc0zehWH2i",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}