{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Making vgg16\n"
      ],
      "metadata": {
        "id": "wqk0fiKdLuWp"
      },
      "id": "wqk0fiKdLuWp"
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision import datasets\n",
        "from torchvision import transforms\n",
        "from torch.utils.data.sampler import SubsetRandomSampler"
      ],
      "metadata": {
        "id": "m724tJ5OLyc1"
      },
      "id": "m724tJ5OLyc1",
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Device config\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "device\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "djwZiAPwMT0A",
        "outputId": "0c7d043f-62a3-44db-bb64-b7becd5868ee"
      },
      "id": "djwZiAPwMT0A",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cpu')"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.datasets as datasets\n",
        "import numpy as np\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "from torch.utils.data.dataloader import DataLoader\n",
        "\n",
        "def data_loader(data_dir, batch_size, random_seed=42, valid_size=0.1, shuffle=True, test=False):\n",
        "    normalize = transforms.Normalize(\n",
        "        mean=[0.4914, 0.4822, 0.4465],\n",
        "        std=[0.2023, 0.1994, 0.2010]\n",
        "    )\n",
        "\n",
        "    transform = transforms.Compose([\n",
        "        transforms.Resize((227, 227)),\n",
        "        transforms.ToTensor(),\n",
        "        normalize\n",
        "    ])\n",
        "\n",
        "    if test:\n",
        "        dataset = datasets.CIFAR10(\n",
        "            root=data_dir, train=False, download=True, transform=transform\n",
        "        )\n",
        "        data_loader = DataLoader(\n",
        "            dataset, batch_size=batch_size, shuffle=shuffle\n",
        "        )\n",
        "        return data_loader\n",
        "    else:\n",
        "        train_dataset = datasets.CIFAR10(\n",
        "            root=data_dir, train=True, download=True, transform=transform\n",
        "        )\n",
        "        val_dataset = datasets.CIFAR10(\n",
        "            root=data_dir, train=True, download=True, transform=transform\n",
        "        )\n",
        "\n",
        "        num_train = len(train_dataset)\n",
        "        indices = list(range(num_train))\n",
        "        split = int(np.floor(valid_size * num_train))\n",
        "\n",
        "        if shuffle:\n",
        "            np.random.seed(random_seed)\n",
        "            np.random.shuffle(indices)\n",
        "\n",
        "        train_idx, val_idx = indices[split:], indices[:split]\n",
        "\n",
        "        train_sampler = SubsetRandomSampler(train_idx)\n",
        "        val_sampler = SubsetRandomSampler(val_idx)\n",
        "\n",
        "        train_loader = DataLoader(\n",
        "            train_dataset, batch_size=batch_size, sampler=train_sampler\n",
        "        )\n",
        "\n",
        "        val_loader = DataLoader(\n",
        "            val_dataset, batch_size=batch_size, sampler=val_sampler\n",
        "        )\n",
        "\n",
        "        return train_loader, val_loader\n",
        "\n",
        "# Example of how to use it:\n",
        "train_loader, val_loader = data_loader(data_dir='./data', batch_size=64)\n",
        "test_loader = data_loader(data_dir='./data', batch_size=64, test=True)\n",
        "\n",
        "print(f\"Train loader has {len(train_loader)} batches.\")\n",
        "print(f\"Validation loader has {len(val_loader)} batches.\")\n",
        "print(f\"Test loader has {len(test_loader)} batches.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wztsAvN4M4dl",
        "outputId": "bcbd2d6b-17c3-4614-af6d-597c27485b83"
      },
      "id": "wztsAvN4M4dl",
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170M/170M [00:02<00:00, 61.0MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loader has 704 batches.\n",
            "Validation loader has 79 batches.\n",
            "Test loader has 157 batches.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class VGG16(nn.Module):\n",
        "  def __init__(self,num_classes = 10):\n",
        "    super(VGG16,self).__init__()\n",
        "\n",
        "    self.layer1 = nn.Sequential(\n",
        "        nn.Conv2d(3,64,kernel_size=3,stride=1,padding=1),\n",
        "        nn.BatchNorm2d(64),\n",
        "        nn.ReLU()\n",
        "    )\n",
        "    self.layer2 = nn.Sequential(\n",
        "        nn.Conv2d(64,64,kernel_size=3,stride=1,padding=1),\n",
        "        nn.BatchNorm2d(64),\n",
        "        nn.ReLU()\n",
        "        nn.MaxPool2d(kernel_size=2,stride=2)\n",
        "    )\n",
        "    self.layer3 = nn.Sequential(\n",
        "        nn.Conv2d(128,128,kernel_size=3,stride=1,padding=1),\n",
        "        nn.BatchNorm2d(128),\n",
        "        nn.ReLU()\n",
        "    )\n",
        "\n",
        "    self.layer4 = nn.Sequential(\n",
        "        nn.Conv2d(128,128,kernel_size=3,stride=1,padding=1),\n",
        "        nn.BatchNorm2d(128),\n",
        "        nn.ReLU()\n",
        "    )\n",
        "\n",
        ""
      ],
      "metadata": {
        "id": "jAPTiUVoWHn7"
      },
      "id": "jAPTiUVoWHn7",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Jv1aGF3JWHzL"
      },
      "id": "Jv1aGF3JWHzL",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BHAc0zehWH2i"
      },
      "id": "BHAc0zehWH2i",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}